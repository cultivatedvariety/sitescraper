# Overview
*sitescraper* is a very basic site scraping engine that renders a sitemap from a resulting scrape.

It consists the following constructs:
**Crawler**
* `CrawlerEngine`: crawls a set of URLs as defined by the `Spider`
* `Spider`:
  * identifies the seed url and domains to crawl
  * parses the crawled content to produce `ContentItem`s
  * generates new urls to crawl while parsing crawled content
* `UrlContents`: a list of `ContentItem`s generated by `Spider` for a url
* `ContentItem`: Item of content generated by a `Spider` when it parses some content
**Sitemap renderer**
* `SitemapRenderer`: renders a site map from list of `UrlContents`

The project has one `Spider`, `WiproSpider` and  one `SitemapRenderer`, `DOTSiteMapRenderer`

# Usage
See `com.acompanysitescraper.Main` for example usage
# Shortcommings
* Randomly generated parameters on urls may result in infinite parsing e.g. if http://mydom.com/index.html?q=1
& http://mydom.com/index.html?q=qqqp result in the same page but the *q* parameter changes every time then the page may be
parsed infinitely. A potential fix is generating a hashcode of the page and not-reparsing if the hashcode hasn't changed

# Improvements
* `CrawlEngine` currently uses one `Executor` for both crawing and parsing. This could be split into two executors so that parsing and crawling are independent
* Better error handling and feedback
* Ability to cancel mid-crawl